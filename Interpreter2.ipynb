{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292d37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.57.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2026.1.14)\n",
      "Requirement already satisfied: requests in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2026.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install typing\n",
    "%pip install re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce214b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from typing import List\n",
    "import torch\n",
    "import re\n",
    "\n",
    "class SentimentModel():\n",
    "    def __init__(self, model_name: str = \"oliverguhr/german-sentiment-bert\"):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'        \n",
    "            \n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.clean_chars = re.compile(r'[^A-Za-züöäÖÜÄß ]', re.MULTILINE)\n",
    "        self.clean_http_urls = re.compile(r'https*\\S+', re.MULTILINE)\n",
    "        self.clean_at_mentions = re.compile(r'@\\S+', re.MULTILINE)\n",
    "\n",
    "    def predict_sentiment(self, texts: List[str], output_probabilities = False)-> List[str]:\n",
    "        texts = [self.clean_text(text) for text in texts]\n",
    "        # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        # truncation=True limits number of tokens to model's limitations (512)\n",
    "        encoded = self.tokenizer.batch_encode_plus(texts,padding=True, add_special_tokens=True,truncation=True, return_tensors=\"pt\")\n",
    "        encoded = encoded.to(self.device)\n",
    "        with torch.no_grad():\n",
    "                logits = self.model(**encoded)\n",
    "        \n",
    "        label_ids = torch.argmax(logits[0], axis=1)\n",
    "\n",
    "        if output_probabilities == False:\n",
    "            return [self.model.config.id2label[label_id.item()] for label_id in label_ids]\n",
    "        else:\n",
    "            predictions = torch.softmax(logits[0], dim=-1).tolist()  \n",
    "            probabilities = []\n",
    "            for prediction in predictions:\n",
    "                probabilities += [[[self.model.config.id2label[index], item] for index, item in enumerate(prediction)]]\n",
    "                \n",
    "            return [self.model.config.id2label[label_id.item()] for label_id in label_ids], probabilities\n",
    "        \n",
    "        \n",
    "    def replace_numbers(self,text: str) -> str:\n",
    "        return text.replace(\"0\",\" null\").replace(\"1\",\" eins\").replace(\"2\",\" zwei\")\\\n",
    "            .replace(\"3\",\" drei\").replace(\"4\",\" vier\").replace(\"5\",\" fünf\") \\\n",
    "            .replace(\"6\",\" sechs\").replace(\"7\",\" sieben\").replace(\"8\",\" acht\") \\\n",
    "            .replace(\"9\",\" neun\")         \n",
    "\n",
    "    def clean_text(self,text: str)-> str:    \n",
    "            text = text.replace(\"\\n\", \" \")        \n",
    "            text = self.clean_http_urls.sub('',text)\n",
    "            text = self.clean_at_mentions.sub('',text)        \n",
    "            text = self.replace_numbers(text)                \n",
    "            text = self.clean_chars.sub('', text) # use only text chars                          \n",
    "            text = ' '.join(text.split()) # substitute multiple whitespace with single whitespace   \n",
    "            text = text.strip().lower()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b94c18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_unlabeled_reddit_posts_from_influx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m written\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Run it:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mlabel_unlabeled_reddit_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m30d\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mlabel_unlabeled_reddit_posts\u001b[39m\u001b[34m(lookback, limit, batch_size)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlabel_unlabeled_reddit_posts\u001b[39m(\n\u001b[32m     17\u001b[39m     lookback: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m30d\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     limit: \u001b[38;5;28mint\u001b[39m = \u001b[32m500\u001b[39m,\n\u001b[32m     19\u001b[39m     batch_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m32\u001b[39m,\n\u001b[32m     20\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     df = \u001b[43mload_unlabeled_reddit_posts_from_influx\u001b[49m(lookback=lookback, limit=limit)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df.empty:\n\u001b[32m     23\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo unlabeled reddit_post points found.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_unlabeled_reddit_posts_from_influx' is not defined"
     ]
    }
   ],
   "source": [
    "from influx_io import load_unlabeled_reddit_posts_from_influx\n",
    "import math\n",
    "\n",
    "# Your class (keep as-is) + create model\n",
    "model = SentimentModel(\"mdraw/german-news-sentiment-bert\")\n",
    "\n",
    "def _pick_conf(prob_list, chosen_label: str) -> float:\n",
    "    \"\"\"\n",
    "    prob_list example: [[\"negative\", 0.12], [\"neutral\", 0.70], [\"positive\", 0.18]]\n",
    "    \"\"\"\n",
    "    for lbl, p in prob_list:\n",
    "        if str(lbl).lower() == str(chosen_label).lower():\n",
    "            return float(p)\n",
    "    return 0.0\n",
    "\n",
    "def label_unlabeled_reddit_posts(\n",
    "    lookback: str = \"30d\",\n",
    "    limit: int = 500,\n",
    "    batch_size: int = 32,\n",
    "):\n",
    "    df = load_unlabeled_reddit_posts_from_influx(lookback=lookback, limit=limit)\n",
    "    if df.empty:\n",
    "        print(\"No unlabeled reddit_post points found.\")\n",
    "        return 0\n",
    "\n",
    "    # Build the text you want to classify (title + selftext)\n",
    "    texts = []\n",
    "    for _, row in df.iterrows():\n",
    "        title = str(row.get(\"title\") or \"\").strip()\n",
    "        body = str(row.get(\"selftext\") or \"\").strip()\n",
    "        combined = (title + \" \" + body).strip()\n",
    "        texts.append(combined if combined else title)\n",
    "\n",
    "    updates = []\n",
    "    total = len(df)\n",
    "\n",
    "    for start in range(0, total, batch_size):\n",
    "        end = min(start + batch_size, total)\n",
    "        batch_texts = texts[start:end]\n",
    "\n",
    "        labels, probs = model.predict_sentiment(batch_texts, output_probabilities=True)\n",
    "\n",
    "        for i in range(start, end):\n",
    "            chosen_label = labels[i - start]\n",
    "            chosen_prob = _pick_conf(probs[i - start], chosen_label)\n",
    "\n",
    "            r = df.iloc[i]\n",
    "            updates.append({\n",
    "                \"usid\": r[\"usid\"],\n",
    "                \"source\": r[\"source\"],\n",
    "                \"_time\": r[\"_time\"],          # IMPORTANT: same timestamp to update the point\n",
    "                \"stance_label\": chosen_label, # store model label\n",
    "                \"stance_conf\": chosen_prob,   # store confidence\n",
    "            })\n",
    "\n",
    "    written = write_reddit_stance_updates(updates)\n",
    "    print(f\"Labeled+updated {written} points.\")\n",
    "    return written\n",
    "\n",
    "# Run it:\n",
    "label_unlabeled_reddit_posts(lookback=\"30d\", limit=2000, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
