{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.0 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.0/44.0 kB 535.7 kB/s eta 0:00:00\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2026.1.14-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB 8.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/12.0 MB 12.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.3/12.0 MB 18.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.8/12.0 MB 22.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.9/12.0 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.3/12.0 MB 23.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.8/12.0 MB 24.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.0 MB 25.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.8/12.0 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.0 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 28.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 566.1/566.1 kB 17.9 MB/s eta 0:00:00\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.8/158.8 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading regex-2026.1.14-cp311-cp311-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 277.8/277.8 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "   ---------------------------------------- 0.0/341.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 341.4/341.4 kB 20.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.5/2.7 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 34.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "   ---------------------------------------- 0.0/201.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 201.8/201.8 kB 12.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, safetensors, regex, pyyaml, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.20.3 fsspec-2026.1.0 huggingface-hub-0.36.0 pyyaml-6.0.3 regex-2026.1.14 safetensors-0.7.0 tokenizers-0.22.2 tqdm-4.67.1 transformers-4.57.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts hf.exe, huggingface-cli.exe and tiny-agents.exe are installed in 'c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts transformers-cli.exe and transformers.exe are installed in 'c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2026.1.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Downloading torch-2.9.1-cp311-cp311-win_amd64.whl (111.0 MB)\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/111.0 MB 2.2 MB/s eta 0:00:51\n",
      "   ---------------------------------------- 0.5/111.0 MB 4.9 MB/s eta 0:00:23\n",
      "    --------------------------------------- 1.4/111.0 MB 10.0 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 2.9/111.0 MB 15.6 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 3.7/111.0 MB 17.1 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 4.5/111.0 MB 15.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 6.7/111.0 MB 20.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 8.3/111.0 MB 22.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 9.8/111.0 MB 23.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 11.2/111.0 MB 29.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 12.7/111.0 MB 29.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 14.1/111.0 MB 38.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 15.6/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 17.1/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 18.6/111.0 MB 32.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 20.0/111.0 MB 32.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 21.5/111.0 MB 32.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 22.9/111.0 MB 32.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 24.4/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 25.9/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 27.3/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 28.8/111.0 MB 31.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 30.2/111.0 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 31.8/111.0 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 33.2/111.0 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 34.7/111.0 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 36.2/111.0 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 37.6/111.0 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 39.1/111.0 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 40.6/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 42.1/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 43.6/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 45.0/111.0 MB 32.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 46.4/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 48.0/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 49.5/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 51.0/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 52.4/111.0 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 54.0/111.0 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 55.4/111.0 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 56.8/111.0 MB 31.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 58.3/111.0 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 59.8/111.0 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 61.3/111.0 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 62.8/111.0 MB 31.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 64.2/111.0 MB 31.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 65.7/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 67.2/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 67.8/111.0 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 68.9/111.0 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 71.5/111.0 MB 32.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 73.0/111.0 MB 32.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 74.5/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 76.0/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 77.5/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 78.9/111.0 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 80.4/111.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 81.9/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 83.4/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 84.9/111.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 86.4/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 87.8/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 89.3/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 90.8/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 92.3/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 93.7/111.0 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 95.2/111.0 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 96.7/111.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 98.1/111.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 99.6/111.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 101.0/111.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 102.5/111.0 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 104.0/111.0 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 105.4/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 106.9/111.0 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  108.4/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.9/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.0/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.0/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.0/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.0/111.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 111.0/111.0 MB 20.4 MB/s eta 0:00:00\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.1 MB 42.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 21.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.1/6.3 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.1/6.3 MB 32.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 28.7 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.9/134.9 kB ? eta 0:00:00\n",
      "Downloading markupsafe-3.0.3-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.3 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 sympy-1.14.0 torch-2.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "     ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/78.6 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 41.0/78.6 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 78.6/78.6 kB 621.4 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: typing\n",
      "  Building wheel for typing (pyproject.toml): started\n",
      "  Building wheel for typing (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26421 sha256=364a12fa2a4e8cb18eb099f390cae338c1e6d306f2d0dda04bb550883b3c5b57\n",
      "  Stored in directory: c:\\users\\martin\\appdata\\local\\pip\\cache\\wheels\\9d\\67\\2f\\53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
      "Successfully built typing\n",
      "Installing collected packages: typing\n",
      "Successfully installed typing-3.7.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install typing\n",
    "%pip install re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce214b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wikto\\AppData\\Local\\Python\\pythoncore-3.10-64\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from typing import List\n",
    "import torch\n",
    "import re\n",
    "\n",
    "class SentimentModel():\n",
    "    def __init__(self, model_name: str = \"oliverguhr/german-sentiment-bert\"):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'        \n",
    "            \n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.clean_chars = re.compile(r'[^A-Za-züöäÖÜÄß ]', re.MULTILINE)\n",
    "        self.clean_http_urls = re.compile(r'https*\\S+', re.MULTILINE)\n",
    "        self.clean_at_mentions = re.compile(r'@\\S+', re.MULTILINE)\n",
    "\n",
    "    def predict_sentiment(self, texts: List[str], output_probabilities = False)-> List[str]:\n",
    "        texts = [self.clean_text(text) for text in texts]\n",
    "        # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        # truncation=True limits number of tokens to model's limitations (512)\n",
    "        encoded = self.tokenizer.batch_encode_plus(texts,padding=True, add_special_tokens=True,truncation=True, return_tensors=\"pt\")\n",
    "        encoded = encoded.to(self.device)\n",
    "        with torch.no_grad():\n",
    "                logits = self.model(**encoded)\n",
    "        \n",
    "        label_ids = torch.argmax(logits[0], axis=1)\n",
    "\n",
    "        if output_probabilities == False:\n",
    "            return [self.model.config.id2label[label_id.item()] for label_id in label_ids]\n",
    "        else:\n",
    "            predictions = torch.softmax(logits[0], dim=-1).tolist()  \n",
    "            probabilities = []\n",
    "            for prediction in predictions:\n",
    "                probabilities += [[[self.model.config.id2label[index], item] for index, item in enumerate(prediction)]]\n",
    "                \n",
    "            return [self.model.config.id2label[label_id.item()] for label_id in label_ids], probabilities\n",
    "        \n",
    "        \n",
    "    def replace_numbers(self,text: str) -> str:\n",
    "        return text.replace(\"0\",\" null\").replace(\"1\",\" eins\").replace(\"2\",\" zwei\")\\\n",
    "            .replace(\"3\",\" drei\").replace(\"4\",\" vier\").replace(\"5\",\" fünf\") \\\n",
    "            .replace(\"6\",\" sechs\").replace(\"7\",\" sieben\").replace(\"8\",\" acht\") \\\n",
    "            .replace(\"9\",\" neun\")         \n",
    "\n",
    "    def clean_text(self,text: str)-> str:    \n",
    "            text = text.replace(\"\\n\", \" \")        \n",
    "            text = self.clean_http_urls.sub('',text)\n",
    "            text = self.clean_at_mentions.sub('',text)        \n",
    "            text = self.replace_numbers(text)                \n",
    "            text = self.clean_chars.sub('', text) # use only text chars                          \n",
    "            text = ' '.join(text.split()) # substitute multiple whitespace with single whitespace   \n",
    "            text = text.strip().lower()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b94c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentimentModel('mdraw/german-news-sentiment-bert')\n",
    "\n",
    "# Examples from our validation dataset\n",
    "texts = ['Trump',]\n",
    "\n",
    "result = model.predict_sentiment(texts)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18401a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers torch influxdb-client\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Tuple\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from influx_io import get_client, INFLUX_BUCKET, INFLUX_ORG, write_reddit_stance_updates\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1) Your model (kept almost same, only small cleanup)\n",
    "# -------------------------\n",
    "import re\n",
    "\n",
    "class SentimentModel:\n",
    "    def __init__(self, model_name: str = \"mdraw/german-news-sentiment-bert\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.clean_chars = re.compile(r\"[^A-Za-züöäÖÜÄß ]\", re.MULTILINE)\n",
    "        self.clean_http_urls = re.compile(r\"https*\\S+\", re.MULTILINE)\n",
    "        self.clean_at_mentions = re.compile(r\"@\\S+\", re.MULTILINE)\n",
    "\n",
    "    def predict_sentiment(self, texts: List[str], output_probabilities: bool = False):\n",
    "        texts = [self.clean_text(t or \"\") for t in texts]\n",
    "\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.model(**encoded)  # out.logits exists\n",
    "\n",
    "        logits = out.logits\n",
    "        label_ids = torch.argmax(logits, dim=1)\n",
    "\n",
    "        labels = [self.model.config.id2label[i.item()] for i in label_ids]\n",
    "\n",
    "        if not output_probabilities:\n",
    "            return labels\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1).tolist()\n",
    "        prob_pairs = []\n",
    "        for row in probs:\n",
    "            prob_pairs.append([[self.model.config.id2label[i], float(p)] for i, p in enumerate(row)])\n",
    "\n",
    "        return labels, prob_pairs\n",
    "\n",
    "    def replace_numbers(self, text: str) -> str:\n",
    "        return (\n",
    "            text.replace(\"0\", \" null\").replace(\"1\", \" eins\").replace(\"2\", \" zwei\")\n",
    "            .replace(\"3\", \" drei\").replace(\"4\", \" vier\").replace(\"5\", \" fünf\")\n",
    "            .replace(\"6\", \" sechs\").replace(\"7\", \" sieben\").replace(\"8\", \" acht\")\n",
    "            .replace(\"9\", \" neun\")\n",
    "        )\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = self.clean_http_urls.sub(\"\", text)\n",
    "        text = self.clean_at_mentions.sub(\"\", text)\n",
    "        text = self.replace_numbers(text)\n",
    "        text = self.clean_chars.sub(\"\", text)\n",
    "        text = \" \".join(text.split())\n",
    "        return text.strip().lower()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2) Influx read: load \"unclassified\" reddit posts\n",
    "# -------------------------\n",
    "def load_unclassified_reddit_posts(\n",
    "    lookback: str = \"30d\",\n",
    "    limit: int = 500,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Returns rows with:\n",
    "      - _time (needed for update!)\n",
    "      - usid, source (tags)\n",
    "      - reddit_id, title, selftext (to build classification input)\n",
    "      - stance_label (maybe empty)\n",
    "    \"\"\"\n",
    "    flux = f\"\"\"\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: -{lookback})\n",
    "  |> filter(fn: (r) => r._measurement == \"reddit_post\")\n",
    "  |> pivot(rowKey: [\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> keep(columns: [\"_time\",\"usid\",\"source\",\"reddit_id\",\"title\",\"selftext\",\"stance_label\",\"stance_conf\"])\n",
    "  |> sort(columns: [\"_time\"], desc: true)\n",
    "  |> limit(n: {int(limit)})\n",
    "\"\"\"\n",
    "\n",
    "    with get_client() as client:\n",
    "        tables = client.query_api().query(flux, org=INFLUX_ORG)\n",
    "\n",
    "    out = []\n",
    "    for t in tables:\n",
    "        for rec in t.records:\n",
    "            v = rec.values\n",
    "            stance_label = v.get(\"stance_label\")\n",
    "\n",
    "            # \"unclassified\" = missing or empty string\n",
    "            if stance_label is None or str(stance_label).strip() == \"\":\n",
    "                out.append({\n",
    "                    \"_time\": v.get(\"_time\"),\n",
    "                    \"usid\": v.get(\"usid\"),\n",
    "                    \"source\": v.get(\"source\"),\n",
    "                    \"reddit_id\": v.get(\"reddit_id\"),\n",
    "                    \"title\": v.get(\"title\") or \"\",\n",
    "                    \"selftext\": v.get(\"selftext\") or \"\",\n",
    "                })\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3) Label mapping + confidence extraction\n",
    "# -------------------------\n",
    "def map_model_label_to_stance(model_label: str) -> str:\n",
    "    \"\"\"\n",
    "    Adapt this mapping to your model's id2label names.\n",
    "    Common ones:\n",
    "      - \"negative\", \"neutral\", \"positive\"\n",
    "      - or \"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"\n",
    "      - or German: \"negativ\", \"neutral\", \"positiv\"\n",
    "    \"\"\"\n",
    "    x = (model_label or \"\").strip().lower()\n",
    "\n",
    "    if \"neg\" in x:\n",
    "        return \"negative\"\n",
    "    if \"pos\" in x:\n",
    "        return \"positive\"\n",
    "    # default\n",
    "    return \"neutral\"\n",
    "\n",
    "\n",
    "def confidence_for_label(prob_pairs: List[List[float]], chosen_label: str) -> float:\n",
    "    \"\"\"\n",
    "    prob_pairs example (per text):\n",
    "      [[\"negative\", 0.1], [\"neutral\", 0.2], [\"positive\", 0.7]]\n",
    "    Return probability for chosen_label (case-insensitive). If not found -> 0.0\n",
    "    \"\"\"\n",
    "    chosen = (chosen_label or \"\").strip().lower()\n",
    "    for lbl, p in prob_pairs:\n",
    "        if str(lbl).strip().lower() == chosen:\n",
    "            return float(p)\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 4) Build input text for classifier\n",
    "# -------------------------\n",
    "def build_input_text(title: str, selftext: str, max_chars: int = 2000) -> str:\n",
    "    \"\"\"\n",
    "    Keep it simple: title + selftext.\n",
    "    Cut to avoid huge texts. (Model is token-limited anyway.)\n",
    "    \"\"\"\n",
    "    t = (title or \"\").strip()\n",
    "    s = (selftext or \"\").strip()\n",
    "    combined = (t + \"\\n\\n\" + s).strip()\n",
    "    if len(combined) > max_chars:\n",
    "        combined = combined[:max_chars]\n",
    "    return combined\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5) Main pipeline: read -> predict -> update\n",
    "# -------------------------\n",
    "def classify_and_update_unclassified(\n",
    "    model_name: str = \"mdraw/german-news-sentiment-bert\",\n",
    "    lookback: str = \"30d\",\n",
    "    batch_size: int = 16,\n",
    "    limit: int = 500,\n",
    ") -> int:\n",
    "    model = SentimentModel(model_name=model_name)\n",
    "\n",
    "    rows = load_unclassified_reddit_posts(lookback=lookback, limit=limit)\n",
    "    if not rows:\n",
    "        print(\"No unclassified reddit posts found.\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"Found {len(rows)} unclassified reddit posts. Classifying...\")\n",
    "\n",
    "    updates: List[Dict] = []\n",
    "\n",
    "    # batch predict\n",
    "    for i in range(0, len(rows), batch_size):\n",
    "        chunk = rows[i:i + batch_size]\n",
    "        texts = [build_input_text(r[\"title\"], r[\"selftext\"]) for r in chunk]\n",
    "\n",
    "        labels, probs = model.predict_sentiment(texts, output_probabilities=True)\n",
    "\n",
    "        for r, model_label, prob_pairs in zip(chunk, labels, probs):\n",
    "            stance = map_model_label_to_stance(model_label)\n",
    "\n",
    "            # confidence: take prob for the chosen stance label\n",
    "            # BUT: stance labels in DB are \"negative/neutral/positive\"\n",
    "            # model labels may differ -> confidence lookup should use model_label\n",
    "            # easiest: take max probability instead (robust)\n",
    "            max_p = max(float(p) for _lbl, p in prob_pairs) if prob_pairs else 0.0\n",
    "\n",
    "            updates.append({\n",
    "                \"article_usid\": r[\"usid\"],      # your writer accepts article_usid OR usid\n",
    "                \"usid\": r[\"usid\"],\n",
    "                \"source\": r[\"source\"],\n",
    "                \"_time\": r[\"_time\"],            # IMPORTANT: same timestamp\n",
    "                \"saved_at_utc\": r[\"_time\"],     # writer checks saved_at_utc OR _time\n",
    "                \"stance_label\": stance,\n",
    "                \"stance_conf\": max_p,\n",
    "            })\n",
    "\n",
    "    written = write_reddit_stance_updates(updates)\n",
    "    print(f\"Updated {written} reddit_post points with stance_label/stance_conf.\")\n",
    "    return written\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Run it\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    classify_and_update_unclassified(\n",
    "        model_name=\"mdraw/german-news-sentiment-bert\",\n",
    "        lookback=\"30d\",\n",
    "        batch_size=16,\n",
    "        limit=500,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
