{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from influx_io import get_client, INFLUX_BUCKET, INFLUX_ORG, ping_influx, write_reddit_stance_updates\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "MODEL_NAME = os.getenv(\"STANCE_MODEL\", \"mdraw/german-news-sentiment-bert\") # IDK WE CAN CHANGE IT BROOOOOOOO\n",
    "LOOKBACK = os.getenv(\"STANCE_LOOKBACK\", \"30d\")          # how far back to scan reddit_post\n",
    "BATCH_SIZE = int(os.getenv(\"STANCE_BATCH_SIZE\", \"32\"))  # tune for your GPU/CPU\n",
    "MAX_LEN = int(os.getenv(\"STANCE_MAX_LEN\", \"256\"))       # keep it fast; reddit text can be long\n",
    "ONLY_UNLABELED = os.getenv(\"STANCE_ONLY_UNLABELED\", \"1\") == \"1\"\n",
    "\n",
    "# If you previously used 0.45 as your \"neutral default\" placeholder, keep it consistent:\n",
    "NEUTRAL_DEFAULT_CONF = float(os.getenv(\"STANCE_NEUTRAL_DEFAULT_CONF\", \"0.45\"))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Text cleaning (simple + safe)\n",
    "# -----------------------------\n",
    "_clean_http_urls = re.compile(r\"https?://\\S+\")\n",
    "_clean_at_mentions = re.compile(r\"@\\S+\")\n",
    "_clean_chars = re.compile(r\"[^0-9A-Za-züöäÖÜÄß\\s]+\", re.MULTILINE)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = _clean_http_urls.sub(\"\", text)\n",
    "    text = _clean_at_mentions.sub(\"\", text)\n",
    "    text = _clean_chars.sub(\" \", text)\n",
    "    text = \" \".join(text.split()).strip().lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "def build_model_input(title: str, selftext: str) -> str:\n",
    "    \"\"\"\n",
    "    Keep it simple: title is strong signal; selftext adds context.\n",
    "    Truncate later via tokenizer max_length anyway.\n",
    "    \"\"\"\n",
    "    title = clean_text(title or \"\")\n",
    "    body = clean_text(selftext or \"\")\n",
    "    if body:\n",
    "        return f\"{title} {body}\"\n",
    "    return title\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load reddit posts from Influx\n",
    "# -----------------------------\n",
    "def load_reddit_posts_df(lookback: str = \"30d\", only_unlabeled: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads measurement reddit_post into a DataFrame with:\n",
    "      _time, usid, source, title, selftext, stance_label, stance_conf\n",
    "    \"\"\"\n",
    "    with get_client() as client:\n",
    "        q = client.query_api()\n",
    "        flux = f\"\"\"\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: -{lookback})\n",
    "  |> filter(fn: (r) => r._measurement == \"reddit_post\")\n",
    "  |> pivot(rowKey: [\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> keep(columns: [\"_time\",\"usid\",\"source\",\"title\",\"selftext\",\"stance_label\",\"stance_conf\"])\n",
    "\"\"\"\n",
    "        tables = q.query(flux, org=INFLUX_ORG)\n",
    "\n",
    "    rows = []\n",
    "    for t in tables:\n",
    "        for rec in t.records:\n",
    "            v = rec.values\n",
    "            rows.append({\n",
    "                \"_time\": v.get(\"_time\"),\n",
    "                \"usid\": v.get(\"usid\"),\n",
    "                \"source\": v.get(\"source\"),\n",
    "                \"title\": v.get(\"title\"),\n",
    "                \"selftext\": v.get(\"selftext\"),\n",
    "                \"stance_label\": v.get(\"stance_label\"),\n",
    "                \"stance_conf\": v.get(\"stance_conf\"),\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Normalize types\n",
    "    df[\"stance_label\"] = df[\"stance_label\"].fillna(\"\").astype(str)\n",
    "    df[\"stance_conf\"] = pd.to_numeric(df[\"stance_conf\"], errors=\"coerce\")\n",
    "\n",
    "    if only_unlabeled:\n",
    "        # classify only those that have no label OR missing conf OR conf==0 OR conf==neutral default placeholder\n",
    "        mask = (\n",
    "            (df[\"stance_label\"].str.strip() == \"\") |\n",
    "            (df[\"stance_conf\"].isna()) |\n",
    "            (df[\"stance_conf\"] == 0) |\n",
    "            (df[\"stance_conf\"] == NEUTRAL_DEFAULT_CONF)\n",
    "        )\n",
    "        df = df[mask].copy()\n",
    "\n",
    "    # Drop rows without minimal identifiers\n",
    "    df = df.dropna(subset=[\"_time\", \"usid\", \"source\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model wrapper (sentiment -> stance)\n",
    "# -----------------------------\n",
    "class StanceClassifier:\n",
    "    \"\"\"\n",
    "    Uses a German sentiment model and maps:\n",
    "      NEGATIVE -> CON\n",
    "      POSITIVE -> PRO\n",
    "      NEUTRAL  -> NEU\n",
    "\n",
    "    NOTE: This is a pragmatic baseline.\n",
    "    True stance \"pro/con\" about an article is not always the same as sentiment.\n",
    "    But it fits your current pipeline and produces stance_label + stance_conf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = MODEL_NAME):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # try to read label mapping from model config\n",
    "        self.id2label = {int(k): v for k, v in self.model.config.id2label.items()} if hasattr(self.model.config, \"id2label\") else {}\n",
    "\n",
    "    def _map_to_stance(self, model_label: str) -> str:\n",
    "        lab = (model_label or \"\").upper()\n",
    "        if \"NEG\" in lab:\n",
    "            return \"CON\"\n",
    "        if \"POS\" in lab:\n",
    "            return \"PRO\"\n",
    "        if \"NEU\" in lab:\n",
    "            return \"NEU\"\n",
    "        # fallback\n",
    "        return \"NEU\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, texts: list[str], batch_size: int = BATCH_SIZE, max_len: int = MAX_LEN) -> Tuple[list[str], list[float]]:\n",
    "        stance_labels: list[str] = []\n",
    "        stance_confs: list[float] = []\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            enc = self.tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "\n",
    "            out = self.model(**enc)\n",
    "            probs = torch.softmax(out.logits, dim=-1)  # [B, C]\n",
    "            best = torch.argmax(probs, dim=-1)         # [B]\n",
    "            best_conf = torch.gather(probs, 1, best.unsqueeze(1)).squeeze(1)  # [B]\n",
    "\n",
    "            for idx, conf in zip(best.tolist(), best_conf.tolist()):\n",
    "                model_label = self.id2label.get(idx, str(idx))\n",
    "                stance_labels.append(self._map_to_stance(model_label))\n",
    "                stance_confs.append(float(conf))\n",
    "\n",
    "        return stance_labels, stance_confs\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# End-to-end: Influx -> classify -> write back\n",
    "# -----------------------------\n",
    "def run_stance_update(\n",
    "    lookback: str = LOOKBACK,\n",
    "    only_unlabeled: bool = ONLY_UNLABELED,\n",
    "    model_name: str = MODEL_NAME\n",
    ") -> pd.DataFrame:\n",
    "    if not ping_influx():\n",
    "        raise RuntimeError(\"InfluxDB ping failed. Check INFLUX_URL / token / org / bucket env vars.\")\n",
    "\n",
    "    df = load_reddit_posts_df(lookback=lookback, only_unlabeled=only_unlabeled)\n",
    "    if df.empty:\n",
    "        print(\"No reddit_post rows to classify (empty DataFrame).\")\n",
    "        return df\n",
    "\n",
    "    # Build model inputs\n",
    "    texts = [\n",
    "        build_model_input(t, s)\n",
    "        for t, s in zip(df[\"title\"].fillna(\"\"), df[\"selftext\"].fillna(\"\"))\n",
    "    ]\n",
    "\n",
    "    clf = StanceClassifier(model_name=model_name)\n",
    "    labels, confs = clf.predict(texts)\n",
    "\n",
    "    df[\"stance_label_new\"] = labels\n",
    "    df[\"stance_conf_new\"] = confs\n",
    "\n",
    "    # Prepare rows for Influx \"update\"\n",
    "    # IMPORTANT: write_reddit_stance_updates requires: usid, source, _time + stance_label/stance_conf\n",
    "    update_rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        update_rows.append({\n",
    "            \"usid\": r[\"usid\"],\n",
    "            \"source\": r[\"source\"],\n",
    "            \"_time\": r[\"_time\"],  # keep the SAME timestamp to update the existing point\n",
    "            \"stance_label\": r[\"stance_label_new\"],\n",
    "            \"stance_conf\": float(r[\"stance_conf_new\"]),\n",
    "        })\n",
    "\n",
    "    written = write_reddit_stance_updates(update_rows)\n",
    "    print(f\"Updated stance for points written: {written} (from rows={len(update_rows)})\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Run it ----\n",
    "df_out = run_stance_update()\n",
    "df_out[[\"_time\",\"usid\",\"source\",\"stance_label_new\",\"stance_conf_new\"]].head(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
