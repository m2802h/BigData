{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed355ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: feedparser in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (6.0.12)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from feedparser) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\martin\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.11.12)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests feedparser\n",
    "%pip install pandas\n",
    "%pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05ce5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - imports + config\n",
    "import os, csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "FEED_URL = \"https://rss.orf.at/news.xml\"\n",
    "CSV_PATH = \"orf_politik_ausland.csv\"\n",
    "\n",
    "TARGET_OEWA = \"urn:oewa:RedCont:Politik/PolitikAusland\"\n",
    "USER_AGENT = \"orf-rss-tracker/1.0 (+local notebook)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8e6fb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18730,\n",
       " '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<rdf:RDF\\n  xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n  xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\\n  xmlns:sy=\"http://purl.org/rss/1.0/modules/synd')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 - fetch XML\n",
    "def fetch_feed_xml(url: str, timeout: int = 20) -> str:\n",
    "    r = requests.get(url, timeout=timeout, headers={\"User-Agent\": USER_AGENT})\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "xml_text = fetch_feed_xml(FEED_URL)\n",
    "len(xml_text), xml_text[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9e60c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
       " 'dc': 'http://purl.org/dc/elements/1.1/',\n",
       " 'sy': 'http://purl.org/rss/1.0/modules/syndication/',\n",
       " 'orfon': 'http://rss.orf.at/1.0/',\n",
       " '': 'http://purl.org/rss/1.0/'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 - detect namespaces robustly (so you don't have to guess)\n",
    "import io\n",
    "\n",
    "def detect_namespaces(xml_text: str) -> dict:\n",
    "    ns = {}\n",
    "    for event, elem in ET.iterparse(io.StringIO(xml_text), events=(\"start-ns\",)):\n",
    "        prefix, uri = elem\n",
    "        ns[prefix if prefix is not None else \"\"] = uri\n",
    "    return ns\n",
    "\n",
    "NS = detect_namespaces(xml_text)\n",
    "NS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78b7f758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF', 30)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 - parse + sanity checks (THIS will show why your old code returned 0)\n",
    "root = ET.fromstring(xml_text)\n",
    "\n",
    "rss_ns = NS.get(\"rss\", \"http://purl.org/rss/1.0/\")  # ORF uses RSS 1.0\n",
    "items = root.findall(\".//{%s}item\" % rss_ns)\n",
    "\n",
    "root.tag, len(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cac45eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5 - helper: load already-seen usids (dedupe)\n",
    "def load_seen_usids(csv_path: str) -> set[str]:\n",
    "    if not os.path.exists(csv_path):\n",
    "        return set()\n",
    "    seen = set()\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if row.get(\"usid\"):\n",
    "                seen.add(row[\"usid\"])\n",
    "    return seen\n",
    "\n",
    "seen_usids = load_seen_usids(CSV_PATH)\n",
    "len(seen_usids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2917efb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,\n",
       " [{'usid': 'news:3416318',\n",
       "   'date': '2026-01-06T09:57:22+01:00',\n",
       "   'link': 'https://orf.at/stories/3416318/',\n",
       "   'title': 'Ein Toter bei Drohnenangriff auf russische Region Twer',\n",
       "   'oewaCategory': 'urn:oewa:RedCont:Politik/PolitikAusland',\n",
       "   'fetched_at_utc': '2026-01-06T09:35:35.476368+00:00'},\n",
       "  {'usid': 'news:3416305',\n",
       "   'date': '2026-01-06T09:38:29+01:00',\n",
       "   'link': 'https://orf.at/stories/3416305/',\n",
       "   'title': 'Niemand wird mit USA um Grönland kämpfen',\n",
       "   'oewaCategory': 'urn:oewa:RedCont:Politik/PolitikAusland',\n",
       "   'fetched_at_utc': '2026-01-06T09:35:35.476368+00:00'}])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 - parse items + filter by oewaCategory\n",
    "def text_of(el):\n",
    "    return el.text.strip() if el is not None and el.text else None\n",
    "\n",
    "def parse_filtered_items(root: ET.Element, ns: dict) -> list[dict]:\n",
    "    rss_ns = ns.get(\"rss\", \"http://purl.org/rss/1.0/\")\n",
    "    rdf_ns = ns.get(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    dc_ns  = ns.get(\"dc\",  \"http://purl.org/dc/elements/1.1/\")\n",
    "    orf_ns = ns.get(\"orfon\")  # must exist in feed; we'll rely on detected value\n",
    "\n",
    "    if not orf_ns:\n",
    "        raise RuntimeError(\"Could not detect 'orfon' namespace in the feed. Check NS dict output.\")\n",
    "\n",
    "    out = []\n",
    "    for item in root.findall(\".//{%s}item\" % rss_ns):\n",
    "        # orfon:oewaCategory rdf:resource=\"...\"\n",
    "        cat_el = item.find(\"{%s}oewaCategory\" % orf_ns)\n",
    "        if cat_el is None:\n",
    "            continue\n",
    "\n",
    "        cat_val = cat_el.attrib.get(\"{%s}resource\" % rdf_ns)\n",
    "        if cat_val != TARGET_OEWA:\n",
    "            continue\n",
    "\n",
    "        title_el = item.find(\"{%s}title\" % rss_ns)\n",
    "        link_el  = item.find(\"{%s}link\" % rss_ns)\n",
    "        date_el  = item.find(\"{%s}date\" % dc_ns)\n",
    "        usid_el  = item.find(\"{%s}usid\" % orf_ns)\n",
    "\n",
    "        out.append({\n",
    "            \"usid\": text_of(usid_el),\n",
    "            \"date\": text_of(date_el),\n",
    "            \"link\": text_of(link_el),\n",
    "            \"title\": text_of(title_el),\n",
    "            \"oewaCategory\": cat_val,\n",
    "            \"fetched_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "filtered_items = parse_filtered_items(root, NS)\n",
    "len(filtered_items), filtered_items[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c61c4bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,\n",
       " [{'usid': 'news:3416318',\n",
       "   'date': '2026-01-06T09:57:22+01:00',\n",
       "   'link': 'https://orf.at/stories/3416318/',\n",
       "   'title': 'Ein Toter bei Drohnenangriff auf russische Region Twer',\n",
       "   'oewaCategory': 'urn:oewa:RedCont:Politik/PolitikAusland',\n",
       "   'fetched_at_utc': '2026-01-06T09:35:35.482812+00:00'},\n",
       "  {'usid': 'news:3416305',\n",
       "   'date': '2026-01-06T09:38:29+01:00',\n",
       "   'link': 'https://orf.at/stories/3416305/',\n",
       "   'title': 'Niemand wird mit USA um Grönland kämpfen',\n",
       "   'oewaCategory': 'urn:oewa:RedCont:Politik/PolitikAusland',\n",
       "   'fetched_at_utc': '2026-01-06T09:35:35.482812+00:00'}])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 - parse items + filter by oewaCategory\n",
    "def text_of(el):\n",
    "    return el.text.strip() if el is not None and el.text else None\n",
    "\n",
    "def parse_filtered_items(root: ET.Element, ns: dict) -> list[dict]:\n",
    "    rss_ns = ns.get(\"rss\", \"http://purl.org/rss/1.0/\")\n",
    "    rdf_ns = ns.get(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    dc_ns  = ns.get(\"dc\",  \"http://purl.org/dc/elements/1.1/\")\n",
    "    orf_ns = ns.get(\"orfon\")  # must exist in feed; we'll rely on detected value\n",
    "\n",
    "    if not orf_ns:\n",
    "        raise RuntimeError(\"Could not detect 'orfon' namespace in the feed. Check NS dict output.\")\n",
    "\n",
    "    out = []\n",
    "    for item in root.findall(\".//{%s}item\" % rss_ns):\n",
    "        # orfon:oewaCategory rdf:resource=\"...\"\n",
    "        cat_el = item.find(\"{%s}oewaCategory\" % orf_ns)\n",
    "        if cat_el is None:\n",
    "            continue\n",
    "\n",
    "        cat_val = cat_el.attrib.get(\"{%s}resource\" % rdf_ns)\n",
    "        if cat_val != TARGET_OEWA:\n",
    "            continue\n",
    "\n",
    "        title_el = item.find(\"{%s}title\" % rss_ns)\n",
    "        link_el  = item.find(\"{%s}link\" % rss_ns)\n",
    "        date_el  = item.find(\"{%s}date\" % dc_ns)\n",
    "        usid_el  = item.find(\"{%s}usid\" % orf_ns)\n",
    "\n",
    "        out.append({\n",
    "            \"usid\": text_of(usid_el),\n",
    "            \"date\": text_of(date_el),\n",
    "            \"link\": text_of(link_el),\n",
    "            \"title\": text_of(title_el),\n",
    "            \"oewaCategory\": cat_val,\n",
    "            \"fetched_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "filtered_items = parse_filtered_items(root, NS)\n",
    "len(filtered_items), filtered_items[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae5cc8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('urn:oewa:RedCont:Politik/PolitikAusland', 17),\n",
       " ('urn:oewa:RedCont:Nachrichten/Chronik', 5),\n",
       " ('urn:oewa:RedCont:KulturUndFreizeit/KulturUeberblick', 2),\n",
       " ('urn:oewa:RedCont:Politik/PolitikInland', 2),\n",
       " ('urn:oewa:RedCont:Wirtschaft/Unternehmensberichterstattung', 1),\n",
       " ('urn:oewa:RedCont:Wirtschaft/AktienUndBoerse', 1),\n",
       " ('urn:oewa:RedCont:KulturUndFreizeit/Musik', 1),\n",
       " ('urn:oewa:RedCont:MedienUndWerbung/Medien', 1)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 - (optional) debug: what categories exist + counts\n",
    "from collections import Counter\n",
    "\n",
    "def category_counts(root: ET.Element, ns: dict) -> Counter:\n",
    "    rss_ns = ns.get(\"rss\", \"http://purl.org/rss/1.0/\")\n",
    "    rdf_ns = ns.get(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    orf_ns = ns.get(\"orfon\")\n",
    "    c = Counter()\n",
    "    for item in root.findall(\".//{%s}item\" % rss_ns):\n",
    "        cat_el = item.find(\"{%s}oewaCategory\" % orf_ns) if orf_ns else None\n",
    "        if cat_el is None:\n",
    "            continue\n",
    "        cat_val = cat_el.attrib.get(\"{%s}resource\" % rdf_ns)\n",
    "        if cat_val:\n",
    "            c[cat_val] += 1\n",
    "    return c\n",
    "\n",
    "counts = category_counts(root, NS)\n",
    "counts.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "797ce463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 'orf_politik_ausland.csv')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 - append only new items to CSV\n",
    "FIELDNAMES = [\"usid\", \"date\", \"link\", \"title\", \"oewaCategory\", \"fetched_at_utc\"]\n",
    "\n",
    "def append_new_items(csv_path: str, items: list[dict], seen: set[str]) -> int:\n",
    "    is_new_file = not os.path.exists(csv_path)\n",
    "\n",
    "    new_rows = []\n",
    "    for it in items:\n",
    "        if not it.get(\"usid\"):\n",
    "            continue\n",
    "        if it[\"usid\"] in seen:\n",
    "            continue\n",
    "        new_rows.append(it)\n",
    "        seen.add(it[\"usid\"])\n",
    "\n",
    "    if not new_rows:\n",
    "        return 0\n",
    "\n",
    "    with open(csv_path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=FIELDNAMES)\n",
    "        if is_new_file:\n",
    "            w.writeheader()\n",
    "        w.writerows(new_rows)\n",
    "\n",
    "    return len(new_rows)\n",
    "\n",
    "added = append_new_items(CSV_PATH, filtered_items, seen_usids)\n",
    "added, CSV_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e7a4467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usid</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>oewaCategory</th>\n",
       "      <th>fetched_at_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>news:3416291</td>\n",
       "      <td>2026-01-05T18:51:14+01:00</td>\n",
       "      <td>https://orf.at/stories/3416291/</td>\n",
       "      <td>Maduro plädiert auf nicht schuldig</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>news:3416290</td>\n",
       "      <td>2026-01-05T18:22:29+01:00</td>\n",
       "      <td>https://orf.at/stories/3416290/</td>\n",
       "      <td>Maduro plädiert vor US-Gericht auf nicht schuldig</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>news:3416289</td>\n",
       "      <td>2026-01-05T18:19:09+01:00</td>\n",
       "      <td>https://orf.at/stories/3416289/</td>\n",
       "      <td>Israel greift Ziele im Libanon und in Gaza an</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>news:3416288</td>\n",
       "      <td>2026-01-05T17:47:58+01:00</td>\n",
       "      <td>https://orf.at/stories/3416288/</td>\n",
       "      <td>UNO-Sicherheitsrat: Dringlichkeitssitzung zu V...</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>news:3416285</td>\n",
       "      <td>2026-01-05T16:48:25+01:00</td>\n",
       "      <td>https://orf.at/stories/3416285/</td>\n",
       "      <td>Schweiz friert mögliche Maduro-Gelder ein</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>news:3416281</td>\n",
       "      <td>2026-01-05T16:26:09+01:00</td>\n",
       "      <td>https://orf.at/stories/3416281/</td>\n",
       "      <td>Selenskyj setzt Geheimdienstchef ab</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>news:3416269</td>\n",
       "      <td>2026-01-05T15:05:52+01:00</td>\n",
       "      <td>https://orf.at/stories/3416269/</td>\n",
       "      <td>Maduro an New Yorker Gericht überstellt</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>news:3416257</td>\n",
       "      <td>2026-01-05T15:05:17+01:00</td>\n",
       "      <td>https://orf.at/stories/3416257/</td>\n",
       "      <td>Opposition bei Übergang im Abseits</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T08:16:27.605362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>news:3416318</td>\n",
       "      <td>2026-01-06T09:57:22+01:00</td>\n",
       "      <td>https://orf.at/stories/3416318/</td>\n",
       "      <td>Ein Toter bei Drohnenangriff auf russische Reg...</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T09:35:35.482812+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>news:3416305</td>\n",
       "      <td>2026-01-06T09:38:29+01:00</td>\n",
       "      <td>https://orf.at/stories/3416305/</td>\n",
       "      <td>Niemand wird mit USA um Grönland kämpfen</td>\n",
       "      <td>urn:oewa:RedCont:Politik/PolitikAusland</td>\n",
       "      <td>2026-01-06T09:35:35.482812+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            usid                       date                             link  \\\n",
       "19  news:3416291  2026-01-05T18:51:14+01:00  https://orf.at/stories/3416291/   \n",
       "20  news:3416290  2026-01-05T18:22:29+01:00  https://orf.at/stories/3416290/   \n",
       "21  news:3416289  2026-01-05T18:19:09+01:00  https://orf.at/stories/3416289/   \n",
       "22  news:3416288  2026-01-05T17:47:58+01:00  https://orf.at/stories/3416288/   \n",
       "23  news:3416285  2026-01-05T16:48:25+01:00  https://orf.at/stories/3416285/   \n",
       "24  news:3416281  2026-01-05T16:26:09+01:00  https://orf.at/stories/3416281/   \n",
       "25  news:3416269  2026-01-05T15:05:52+01:00  https://orf.at/stories/3416269/   \n",
       "26  news:3416257  2026-01-05T15:05:17+01:00  https://orf.at/stories/3416257/   \n",
       "27  news:3416318  2026-01-06T09:57:22+01:00  https://orf.at/stories/3416318/   \n",
       "28  news:3416305  2026-01-06T09:38:29+01:00  https://orf.at/stories/3416305/   \n",
       "\n",
       "                                                title  \\\n",
       "19                 Maduro plädiert auf nicht schuldig   \n",
       "20  Maduro plädiert vor US-Gericht auf nicht schuldig   \n",
       "21      Israel greift Ziele im Libanon und in Gaza an   \n",
       "22  UNO-Sicherheitsrat: Dringlichkeitssitzung zu V...   \n",
       "23          Schweiz friert mögliche Maduro-Gelder ein   \n",
       "24                Selenskyj setzt Geheimdienstchef ab   \n",
       "25            Maduro an New Yorker Gericht überstellt   \n",
       "26                 Opposition bei Übergang im Abseits   \n",
       "27  Ein Toter bei Drohnenangriff auf russische Reg...   \n",
       "28           Niemand wird mit USA um Grönland kämpfen   \n",
       "\n",
       "                               oewaCategory                    fetched_at_utc  \n",
       "19  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "20  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "21  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "22  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "23  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "24  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "25  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "26  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T08:16:27.605362+00:00  \n",
       "27  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T09:35:35.482812+00:00  \n",
       "28  urn:oewa:RedCont:Politik/PolitikAusland  2026-01-06T09:35:35.482812+00:00  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9 - show latest rows quickly\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915f4e1",
   "metadata": {},
   "source": [
    "Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9d51ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefetched r/politics new: 800 posts\n",
      "Prefetched r/austria new: 800 posts\n",
      "Prefetched r/europe new: 800 posts\n",
      "Prefetched r/worldnews new: 800 posts\n",
      "Prefetched r/news new: 800 posts\n",
      "[1/29] news:3415936 | groups_used=7/7 | scanned_total=5522 | kept=87\n",
      "[2/29] news:3415934 | groups_used=7/7 | scanned_total=6246 | kept=1280\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[3/29] news:3415933 | groups_used=7/7 | scanned_total=6183 | kept=1201\n",
      "[4/29] news:3415931 | groups_used=7/7 | scanned_total=6168 | kept=1298\n",
      "[5/29] news:3415923 | groups_used=7/7 | scanned_total=5117 | kept=128\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[6/29] news:3415915 | groups_used=7/7 | scanned_total=5331 | kept=933\n",
      "[7/29] news:3415913 | groups_used=7/7 | scanned_total=5927 | kept=38\n",
      "[8/29] news:3415907 | groups_used=7/7 | scanned_total=5745 | kept=412\n",
      "[9/29] news:3415898 | groups_used=7/7 | scanned_total=5812 | kept=1576\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[10/29] news:3415894 | groups_used=7/7 | scanned_total=5370 | kept=307\n",
      "[11/29] news:3416307 | groups_used=7/7 | scanned_total=6142 | kept=1227\n",
      "[12/29] news:3416303 | groups_used=7/7 | scanned_total=5368 | kept=124\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[13/29] news:3416302 | groups_used=7/7 | scanned_total=5119 | kept=242\n",
      "[14/29] news:3416301 | groups_used=7/7 | scanned_total=4787 | kept=476\n",
      "[15/29] news:3416242 | groups_used=7/7 | scanned_total=5444 | kept=812\n",
      "[16/29] news:3416250 | groups_used=3/7 | scanned_total=4657 | kept=0\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[17/29] news:3416296 | groups_used=7/7 | scanned_total=6099 | kept=1515\n",
      "[18/29] news:3416295 | groups_used=7/7 | scanned_total=5640 | kept=348\n",
      "[19/29] news:3416294 | groups_used=7/7 | scanned_total=5220 | kept=38\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[20/29] news:3416291 | groups_used=5/7 | scanned_total=5556 | kept=296\n",
      "[21/29] news:3416290 | groups_used=7/7 | scanned_total=6130 | kept=1232\n",
      "[22/29] news:3416289 | groups_used=7/7 | scanned_total=5259 | kept=267\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[23/29] news:3416288 | groups_used=7/7 | scanned_total=4886 | kept=52\n",
      "[24/29] news:3416285 | groups_used=7/7 | scanned_total=6005 | kept=743\n",
      "[25/29] news:3416281 | groups_used=5/7 | scanned_total=6220 | kept=290\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "[26/29] news:3416269 | groups_used=7/7 | scanned_total=5584 | kept=471\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[27/29] news:3416257 | groups_used=5/7 | scanned_total=5755 | kept=229\n",
      "[28/29] news:3416318 | groups_used=7/7 | scanned_total=6363 | kept=1961\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "⚠️ 429 again. Skipping this request.\n",
      "⚠️ 429 rate limit. Backing off...\n",
      "[29/29] news:3416305 | groups_used=7/7 | scanned_total=6025 | kept=995\n",
      "Wrote 18578 rows to reddit_posts_minimal.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# RUN SCRIPT (full)\n",
    "# =========================\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from googletrans import Translator\n",
    "\n",
    "# df already exists:\n",
    "# df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "OUT_CSV = \"reddit_posts_minimal.csv\"\n",
    "USER_AGENT = \"orf-reddit-minimal/1.0\"\n",
    "\n",
    "TITLE_COL = \"title\"\n",
    "USID_COL = \"usid\"\n",
    "\n",
    "# --- Rate limiting ---\n",
    "REQUEST_SLEEP = 2.0      # <- normal sleep between EVERY reddit request\n",
    "BACKOFF_SLEEP = 90       # <- sleep when 429 happens\n",
    "\n",
    "# --- groups / matching ---\n",
    "MAX_KEYWORDS_DE = 20          # extract more DE keywords from title\n",
    "ADD_BIGRAM_GROUPS = True      # add phrase/bigram groups to reach ~7+ groups\n",
    "MAX_BIGRAMS = 10              # cap bigram groups per article\n",
    "\n",
    "TARGET_GROUPS = 7             # try to use 7 groups\n",
    "MIN_GROUP_MATCHES = 3         # must hit at least 3 groups\n",
    "MAX_POST_WORDS = 300          # only keep posts with <= 300 words in checked text\n",
    "\n",
    "CHECK_TEXT_MODE = \"title+selftext\"  # or \"selftext\"\n",
    "\n",
    "# --- reddit search (ranked) ---\n",
    "MAX_PAGES_PER_SOURCE = 10\n",
    "LIMIT_PER_PAGE = 100\n",
    "SORT_MODE = \"relevance\"\n",
    "\n",
    "# --- reddit subreddit feeds (/new.json) ---\n",
    "USE_SUB_NEW_FEEDS = True\n",
    "NEW_FEED_PAGES_PER_SUB = 8\n",
    "NEW_FEED_LIMIT = 100\n",
    "\n",
    "# --- where to search ---\n",
    "SUBREDDITS = [\"politics\", \"austria\", \"europe\", \"worldnews\", \"news\"]\n",
    "SEARCH_GLOBAL_TOO = True\n",
    "RESTRICT_TO_SUBS_ONLY = False\n",
    "\n",
    "# If you delete the CSV after each run, keep False\n",
    "DEDUPE_WITH_EXISTING_CSV = False\n",
    "\n",
    "# =========================\n",
    "# INIT\n",
    "# =========================\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": USER_AGENT})\n",
    "translator = Translator()\n",
    "\n",
    "STOPWORDS = {\n",
    "    # DE\n",
    "    \"der\",\"die\",\"das\",\"und\",\"oder\",\"nicht\",\"nur\",\"auch\",\"mit\",\"von\",\"für\",\"über\",\"unter\",\"nach\",\"vor\",\n",
    "    \"ein\",\"eine\",\"einer\",\"eines\",\"dem\",\"den\",\"des\",\"im\",\"in\",\"am\",\"an\",\"auf\",\"aus\",\"bei\",\"zum\",\"zur\",\n",
    "    \"ist\",\"sind\",\"war\",\"waren\",\"wird\",\"werden\",\"hat\",\"haben\",\"kann\",\"können\",\"muss\",\"müssen\",\n",
    "    # EN\n",
    "    \"the\",\"and\",\"or\",\"not\",\"only\",\"also\",\"with\",\"from\",\"for\",\"about\",\"this\",\"that\",\"these\",\"those\",\n",
    "    \"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"has\",\"have\",\"had\",\"can\",\"could\",\"must\",\"will\",\"may\",\n",
    "    \"of\",\"by\",\"to\",\"in\",\"on\",\"at\"\n",
    "}\n",
    "\n",
    "WORD_RE = re.compile(r\"\\b[\\wÄÖÜäöüß]+\\b\", flags=re.UNICODE)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def safe_str(x) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x)\n",
    "\n",
    "\n",
    "def words_list(text: str) -> list[str]:\n",
    "    return WORD_RE.findall((text or \"\").strip())\n",
    "\n",
    "\n",
    "def tokenize_list(text: str) -> list[str]:\n",
    "    \"\"\"Ordered tokens, lowercased, stopwords removed, len>=3.\"\"\"\n",
    "    text = (text or \"\").lower()\n",
    "    text = re.sub(r\"[^0-9a-zäöüß]+\", \" \", text, flags=re.IGNORECASE)\n",
    "    toks = []\n",
    "    for t in text.split():\n",
    "        if len(t) >= 3 and t not in STOPWORDS:\n",
    "            toks.append(t)\n",
    "    return toks\n",
    "\n",
    "\n",
    "def tokenize_set(text: str) -> set[str]:\n",
    "    return set(tokenize_list(text))\n",
    "\n",
    "\n",
    "def normalize_term_variants(term: str) -> set[str]:\n",
    "    \"\"\"\n",
    "    Lightweight variants:\n",
    "    - lower\n",
    "    - naive plural/singular + DE endings trimming\n",
    "    \"\"\"\n",
    "    t = (term or \"\").strip().lower()\n",
    "    if not t:\n",
    "        return set()\n",
    "    vars_ = {t}\n",
    "\n",
    "    # EN plural -> singular heuristic\n",
    "    if t.endswith(\"s\") and len(t) > 3:\n",
    "        vars_.add(t[:-1])\n",
    "\n",
    "    # DE common endings heuristic\n",
    "    for suf in (\"en\", \"er\", \"e\", \"n\", \"s\"):\n",
    "        if t.endswith(suf) and len(t) > len(suf) + 2:\n",
    "            vars_.add(t[: -len(suf)])\n",
    "\n",
    "    return {v for v in vars_ if len(v) >= 3 and v not in STOPWORDS}\n",
    "\n",
    "\n",
    "def build_keywords_de(title: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Deterministic DE keywords:\n",
    "    - unique tokens\n",
    "    - prefer longer tokens\n",
    "    \"\"\"\n",
    "    toks = tokenize_list(title)\n",
    "    uniq = []\n",
    "    seen = set()\n",
    "    for t in toks:\n",
    "        if t not in seen:\n",
    "            uniq.append(t)\n",
    "            seen.add(t)\n",
    "    uniq_sorted = sorted(uniq, key=lambda x: (-len(x), x))\n",
    "    return uniq_sorted[:MAX_KEYWORDS_DE]\n",
    "\n",
    "\n",
    "def translate_text_de_to_en(text: str) -> str | None:\n",
    "    \"\"\"Best-effort translation; returns None on failure/empty.\"\"\"\n",
    "    try:\n",
    "        t = translator.translate(text, src=\"de\", dest=\"en\").text\n",
    "        t = (t or \"\").strip().lower()\n",
    "        return t if t else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def translate_keywords_to_en(keywords_de: list[str]) -> dict[str, str]:\n",
    "    \"\"\"Mapping {de_kw: en_kw} best-effort.\"\"\"\n",
    "    m = {}\n",
    "    for kw in keywords_de:\n",
    "        t = translate_text_de_to_en(kw)\n",
    "        if t:\n",
    "            m[kw] = t\n",
    "    return m\n",
    "\n",
    "\n",
    "def build_bigram_phrases(title: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Build phrase candidates from title tokens in order.\n",
    "    \"\"\"\n",
    "    toks = tokenize_list(title)\n",
    "    bigrams = []\n",
    "    for i in range(len(toks) - 1):\n",
    "        bigrams.append(f\"{toks[i]} {toks[i+1]}\")\n",
    "    bigrams = sorted(list(dict.fromkeys(bigrams)), key=lambda x: (-len(x), x))\n",
    "    return bigrams[:MAX_BIGRAMS]\n",
    "\n",
    "\n",
    "def build_keyword_groups_from_title(title: str) -> tuple[list[set[str]], dict[str, str], list[str]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - groups (list[set[str]])  : synonym groups (unigrams + optional bigrams)\n",
    "      - de_to_en_map (dict)      : mapping for unigrams and bigrams that were translated\n",
    "      - debug_reps (list[str])   : representative term per group (for logging)\n",
    "    \"\"\"\n",
    "    keywords_de = build_keywords_de(title)\n",
    "    de_to_en = translate_keywords_to_en(keywords_de)\n",
    "\n",
    "    groups: list[set[str]] = []\n",
    "\n",
    "    # unigram groups\n",
    "    for de_kw in keywords_de:\n",
    "        g = set()\n",
    "        g |= normalize_term_variants(de_kw)\n",
    "        en_kw = de_to_en.get(de_kw)\n",
    "        if en_kw:\n",
    "            g |= normalize_term_variants(en_kw)\n",
    "        if g:\n",
    "            groups.append(g)\n",
    "\n",
    "    # bigram groups\n",
    "    if ADD_BIGRAM_GROUPS:\n",
    "        for bg_de in build_bigram_phrases(title):\n",
    "            g = set()\n",
    "            g.add(bg_de.lower())\n",
    "            for tok in tokenize_list(bg_de):\n",
    "                g |= normalize_term_variants(tok)\n",
    "\n",
    "            bg_en = translate_text_de_to_en(bg_de)\n",
    "            if bg_en:\n",
    "                de_to_en[bg_de] = bg_en\n",
    "                g.add(bg_en.lower())\n",
    "                for tok in tokenize_list(bg_en):\n",
    "                    g |= normalize_term_variants(tok)\n",
    "\n",
    "            groups.append(g)\n",
    "\n",
    "    # dedupe identical groups\n",
    "    uniq = []\n",
    "    seen = set()\n",
    "    for g in groups:\n",
    "        key = tuple(sorted(g))\n",
    "        if key not in seen:\n",
    "            uniq.append(g)\n",
    "            seen.add(key)\n",
    "    groups = uniq\n",
    "\n",
    "    # sort groups by specificity (longest representative)\n",
    "    scored = []\n",
    "    for g in groups:\n",
    "        rep = sorted(g, key=lambda x: (-len(x), x))[0]\n",
    "        scored.append((len(rep), rep, g))\n",
    "    scored.sort(reverse=True)\n",
    "\n",
    "    picked = [g for _, _, g in scored[:TARGET_GROUPS]]\n",
    "    reps = [rep for _, rep, _ in scored[:TARGET_GROUPS]]\n",
    "\n",
    "    return picked, de_to_en, reps\n",
    "\n",
    "\n",
    "def group_hit_count(tokens: set[str], groups: list[set[str]]) -> int:\n",
    "    return sum(1 for g in groups if (tokens & g))\n",
    "\n",
    "\n",
    "def get_check_text(post: dict) -> str:\n",
    "    \"\"\"\n",
    "    Include URL as extra matchable text (important for link posts).\n",
    "    \"\"\"\n",
    "    title = safe_str(post.get(\"title\", \"\"))\n",
    "    selftext = safe_str(post.get(\"selftext\", \"\"))\n",
    "    url = safe_str(post.get(\"url\", \"\"))\n",
    "\n",
    "    base = selftext if CHECK_TEXT_MODE == \"selftext\" else f\"{title} {selftext}\".strip()\n",
    "    return f\"{base} {url}\".strip()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# REQUEST WRAPPER (rate limited)\n",
    "# =========================\n",
    "def reddit_get(url: str, *, params: dict | None = None, timeout: int = 30):\n",
    "    \"\"\"\n",
    "    Always sleeps REQUEST_SLEEP after each request.\n",
    "    On 429, sleeps BACKOFF_SLEEP and retries once.\n",
    "    Returns response or None if still 429/failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = session.get(url, params=params, timeout=timeout)\n",
    "        time.sleep(REQUEST_SLEEP)\n",
    "\n",
    "        if r.status_code == 429:\n",
    "            print(\"⚠️ 429 rate limit. Backing off...\")\n",
    "            time.sleep(BACKOFF_SLEEP)\n",
    "            r = session.get(url, params=params, timeout=timeout)\n",
    "            time.sleep(REQUEST_SLEEP)\n",
    "\n",
    "        if r.status_code == 429:\n",
    "            print(\"⚠️ 429 again. Skipping this request.\")\n",
    "            return None\n",
    "\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# REDDIT FETCHERS\n",
    "# =========================\n",
    "def reddit_search(query: str, subreddit: str | None = None):\n",
    "    \"\"\"Search either globally or within a subreddit.\"\"\"\n",
    "    if subreddit:\n",
    "        base = f\"https://www.reddit.com/r/{subreddit}/search.json\"\n",
    "    else:\n",
    "        base = \"https://www.reddit.com/search.json\"\n",
    "\n",
    "    after = None\n",
    "    for _ in range(MAX_PAGES_PER_SOURCE):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"sort\": SORT_MODE,\n",
    "            \"limit\": LIMIT_PER_PAGE,\n",
    "            \"syntax\": \"lucene\",\n",
    "        }\n",
    "        if subreddit:\n",
    "            params[\"restrict_sr\"] = 1\n",
    "        if after:\n",
    "            params[\"after\"] = after\n",
    "\n",
    "        r = reddit_get(base, params=params)\n",
    "        if r is None:\n",
    "            return\n",
    "\n",
    "        data = r.json().get(\"data\", {})\n",
    "        children = data.get(\"children\", [])\n",
    "        if not children:\n",
    "            return\n",
    "\n",
    "        for ch in children:\n",
    "            yield ch.get(\"data\", {})\n",
    "\n",
    "        after = data.get(\"after\")\n",
    "        if not after:\n",
    "            return\n",
    "\n",
    "\n",
    "def iter_posts_for_query(query: str):\n",
    "    \"\"\"Global + subreddit search; dedupe across sources by reddit_id.\"\"\"\n",
    "    seen = set()\n",
    "\n",
    "    if SEARCH_GLOBAL_TOO and not RESTRICT_TO_SUBS_ONLY:\n",
    "        for p in reddit_search(query, subreddit=None):\n",
    "            rid = safe_str(p.get(\"id\"))\n",
    "            if rid and rid not in seen:\n",
    "                seen.add(rid)\n",
    "                yield p\n",
    "\n",
    "    for sub in SUBREDDITS:\n",
    "        for p in reddit_search(query, subreddit=sub):\n",
    "            rid = safe_str(p.get(\"id\"))\n",
    "            if rid and rid not in seen:\n",
    "                seen.add(rid)\n",
    "                yield p\n",
    "\n",
    "\n",
    "def subreddit_new_feed(subreddit: str, pages: int = NEW_FEED_PAGES_PER_SUB, limit: int = NEW_FEED_LIMIT):\n",
    "    \"\"\"Iterate newest posts from a subreddit feed (bypasses search limits).\"\"\"\n",
    "    base = f\"https://www.reddit.com/r/{subreddit}/new.json\"\n",
    "    after = None\n",
    "\n",
    "    for _ in range(pages):\n",
    "        params = {\"limit\": limit}\n",
    "        if after:\n",
    "            params[\"after\"] = after\n",
    "\n",
    "        r = reddit_get(base, params=params)\n",
    "        if r is None:\n",
    "            return\n",
    "\n",
    "        data = r.json().get(\"data\", {})\n",
    "        children = data.get(\"children\", [])\n",
    "        if not children:\n",
    "            return\n",
    "\n",
    "        for ch in children:\n",
    "            yield ch.get(\"data\", {})\n",
    "\n",
    "        after = data.get(\"after\")\n",
    "        if not after:\n",
    "            return\n",
    "\n",
    "\n",
    "def prefetch_new_feeds(subreddits: list[str]) -> dict[str, list[dict]]:\n",
    "    \"\"\"Prefetch new posts once per run so each article can filter locally.\"\"\"\n",
    "    cache: dict[str, list[dict]] = {}\n",
    "    for sub in subreddits:\n",
    "        posts = []\n",
    "        seen = set()\n",
    "        try:\n",
    "            for p in subreddit_new_feed(sub):\n",
    "                rid = safe_str(p.get(\"id\"))\n",
    "                if rid and rid not in seen:\n",
    "                    seen.add(rid)\n",
    "                    posts.append(p)\n",
    "        except Exception as e:\n",
    "            print(f\"Prefetch error for r/{sub}: {e}\")\n",
    "        cache[sub] = posts\n",
    "        print(f\"Prefetched r/{sub} new: {len(posts)} posts\")\n",
    "    return cache\n",
    "\n",
    "\n",
    "# =========================\n",
    "# OPTIONAL DEDUPE WITH EXISTING CSV\n",
    "# =========================\n",
    "existing_pairs = set()\n",
    "if DEDUPE_WITH_EXISTING_CSV and os.path.exists(OUT_CSV):\n",
    "    existing = pd.read_csv(OUT_CSV, encoding=\"utf-8\")\n",
    "    if {\"article_usid\", \"reddit_id\"}.issubset(existing.columns):\n",
    "        existing_pairs = set(zip(existing[\"article_usid\"].astype(str), existing[\"reddit_id\"].astype(str)))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PREFETCH /new.json POSTS\n",
    "# =========================\n",
    "new_feed_cache = {}\n",
    "if USE_SUB_NEW_FEEDS:\n",
    "    new_feed_cache = prefetch_new_feeds(SUBREDDITS)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "rows = []\n",
    "\n",
    "for idx, r in df.iterrows():\n",
    "    article_usid = safe_str(r.get(USID_COL))\n",
    "    article_title = safe_str(r.get(TITLE_COL))\n",
    "    if not article_usid or not article_title:\n",
    "        continue\n",
    "\n",
    "    groups, de_to_en_map, group_reps = build_keyword_groups_from_title(article_title)\n",
    "    if len(groups) < MIN_GROUP_MATCHES:\n",
    "        print(f\"[{idx+1}/{len(df)}] {article_usid} skipped (only {len(groups)} groups)\")\n",
    "        continue\n",
    "\n",
    "    # Build DE & EN queries\n",
    "    reps = group_reps[:]\n",
    "    reps_de = [t for t in reps if (re.search(r\"[äöüß]\", t) or t in tokenize_set(article_title))]\n",
    "    if len(reps_de) < 3:\n",
    "        reps_de = reps[:]\n",
    "    reps_de = reps_de[:TARGET_GROUPS]\n",
    "\n",
    "    en_candidates = sorted({v for v in de_to_en_map.values() if v}, key=lambda x: (-len(x), x))\n",
    "    reps_en = en_candidates[:TARGET_GROUPS] if len(en_candidates) >= 3 else reps[:TARGET_GROUPS]\n",
    "\n",
    "    query_de = \"(\" + \" OR \".join(f\"\\\"{k}\\\"\" for k in reps_de) + \")\"\n",
    "    query_en = \"(\" + \" OR \".join(f\"\\\"{k}\\\"\" for k in reps_en) + \")\"\n",
    "\n",
    "    candidates: dict[str, tuple[dict, str]] = {}  # rid -> (post, source)\n",
    "\n",
    "    def add_candidates_from_iter(it, source: str):\n",
    "        for p in it:\n",
    "            rid = safe_str(p.get(\"id\"))\n",
    "            if not rid:\n",
    "                continue\n",
    "            if rid not in candidates:\n",
    "                candidates[rid] = (p, source)\n",
    "\n",
    "    # searches\n",
    "    add_candidates_from_iter(iter_posts_for_query(query_de), \"search_de\")\n",
    "    add_candidates_from_iter(iter_posts_for_query(query_en), \"search_en\")\n",
    "\n",
    "    # new feeds\n",
    "    if USE_SUB_NEW_FEEDS:\n",
    "        for sub, posts in new_feed_cache.items():\n",
    "            for p in posts:\n",
    "                rid = safe_str(p.get(\"id\"))\n",
    "                if rid and rid not in candidates:\n",
    "                    candidates[rid] = (p, f\"new_{sub}\")\n",
    "\n",
    "    scanned_total = len(candidates)\n",
    "    kept = 0\n",
    "\n",
    "    for rid, (post, source) in candidates.items():\n",
    "        if DEDUPE_WITH_EXISTING_CSV and (article_usid, rid) in existing_pairs:\n",
    "            continue\n",
    "\n",
    "        text = get_check_text(post)\n",
    "        words = words_list(text)\n",
    "        if len(words) > MAX_POST_WORDS:\n",
    "            continue\n",
    "\n",
    "        window_text = \" \".join(words[:MAX_POST_WORDS])\n",
    "        tokens = tokenize_set(window_text)\n",
    "\n",
    "        matches = group_hit_count(tokens, groups)\n",
    "        if matches < MIN_GROUP_MATCHES:\n",
    "            continue\n",
    "\n",
    "        matched_reps = []\n",
    "        for g, rep in zip(groups, group_reps):\n",
    "            if tokens & g:\n",
    "                matched_reps.append(rep)\n",
    "\n",
    "        rows.append({\n",
    "            \"article_usid\": article_usid,\n",
    "            \"reddit_id\": rid,\n",
    "            \"reddit_title\": safe_str(post.get(\"title\", \"\")),\n",
    "            \"reddit_selftext\": safe_str(post.get(\"selftext\", \"\")),\n",
    "            \"post_url\": safe_str(post.get(\"url\", \"\")),\n",
    "            \"reddit_permalink\": \"https://www.reddit.com\" + safe_str(post.get(\"permalink\", \"\")),\n",
    "            \"source\": source,\n",
    "            \"checked_word_count\": len(words),\n",
    "            \"groups_used\": len(groups),\n",
    "            \"group_matches_in_window\": matches,\n",
    "            \"matched_group_reps\": \",\".join(matched_reps),\n",
    "            \"query_de\": query_de,\n",
    "            \"query_en\": query_en,\n",
    "            \"saved_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "        })\n",
    "        kept += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{idx+1}/{len(df)}] {article_usid} | \"\n",
    "        f\"groups_used={len(groups)}/{TARGET_GROUPS} | \"\n",
    "        f\"scanned_total={scanned_total} | kept={kept}\"\n",
    "    )\n",
    "\n",
    "# Write CSV\n",
    "if rows:\n",
    "    out = pd.DataFrame(rows)\n",
    "    file_exists = os.path.exists(OUT_CSV)\n",
    "    out.to_csv(\n",
    "        OUT_CSV,\n",
    "        mode=\"a\" if file_exists else \"w\",\n",
    "        header=not file_exists,\n",
    "        index=False,\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(f\"Wrote {len(out)} rows to {OUT_CSV}\")\n",
    "else:\n",
    "    print(\"No matching posts found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39d11fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 18578\n",
      "Unique articles: 28\n",
      "Unique reddit posts: 16230\n",
      "\n",
      "Top sources:\n",
      "source\n",
      "search_en        9346\n",
      "search_de        7339\n",
      "new_worldnews     534\n",
      "new_politics      492\n",
      "new_europe        334\n",
      "new_austria       272\n",
      "new_news          261\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kept</th>\n",
       "      <th>avg_group_matches</th>\n",
       "      <th>avg_word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_usid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>news:3416318</th>\n",
       "      <td>1961</td>\n",
       "      <td>3.211117</td>\n",
       "      <td>34.694034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3415898</th>\n",
       "      <td>1576</td>\n",
       "      <td>4.286802</td>\n",
       "      <td>37.378173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416296</th>\n",
       "      <td>1515</td>\n",
       "      <td>3.098350</td>\n",
       "      <td>44.458086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3415931</th>\n",
       "      <td>1298</td>\n",
       "      <td>3.025424</td>\n",
       "      <td>45.759630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3415934</th>\n",
       "      <td>1280</td>\n",
       "      <td>3.073437</td>\n",
       "      <td>44.971875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416290</th>\n",
       "      <td>1232</td>\n",
       "      <td>3.362825</td>\n",
       "      <td>37.194805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416307</th>\n",
       "      <td>1227</td>\n",
       "      <td>3.007335</td>\n",
       "      <td>42.270579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3415933</th>\n",
       "      <td>1201</td>\n",
       "      <td>3.129892</td>\n",
       "      <td>36.096586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416305</th>\n",
       "      <td>995</td>\n",
       "      <td>3.023116</td>\n",
       "      <td>42.782915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3415915</th>\n",
       "      <td>933</td>\n",
       "      <td>3.096463</td>\n",
       "      <td>49.154341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416242</th>\n",
       "      <td>812</td>\n",
       "      <td>3.057882</td>\n",
       "      <td>44.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416285</th>\n",
       "      <td>743</td>\n",
       "      <td>3.049798</td>\n",
       "      <td>63.328398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416301</th>\n",
       "      <td>476</td>\n",
       "      <td>3.138655</td>\n",
       "      <td>33.132353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416269</th>\n",
       "      <td>471</td>\n",
       "      <td>3.524416</td>\n",
       "      <td>41.123142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3415907</th>\n",
       "      <td>412</td>\n",
       "      <td>3.526699</td>\n",
       "      <td>84.898058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416295</th>\n",
       "      <td>348</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>57.227011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3415894</th>\n",
       "      <td>307</td>\n",
       "      <td>3.403909</td>\n",
       "      <td>38.368078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416291</th>\n",
       "      <td>296</td>\n",
       "      <td>3.760135</td>\n",
       "      <td>34.277027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416281</th>\n",
       "      <td>290</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>60.313793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news:3416289</th>\n",
       "      <td>267</td>\n",
       "      <td>3.239700</td>\n",
       "      <td>36.168539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              kept  avg_group_matches  avg_word_count\n",
       "article_usid                                         \n",
       "news:3416318  1961           3.211117       34.694034\n",
       "news:3415898  1576           4.286802       37.378173\n",
       "news:3416296  1515           3.098350       44.458086\n",
       "news:3415931  1298           3.025424       45.759630\n",
       "news:3415934  1280           3.073437       44.971875\n",
       "news:3416290  1232           3.362825       37.194805\n",
       "news:3416307  1227           3.007335       42.270579\n",
       "news:3415933  1201           3.129892       36.096586\n",
       "news:3416305   995           3.023116       42.782915\n",
       "news:3415915   933           3.096463       49.154341\n",
       "news:3416242   812           3.057882       44.071429\n",
       "news:3416285   743           3.049798       63.328398\n",
       "news:3416301   476           3.138655       33.132353\n",
       "news:3416269   471           3.524416       41.123142\n",
       "news:3415907   412           3.526699       84.898058\n",
       "news:3416295   348           3.166667       57.227011\n",
       "news:3415894   307           3.403909       38.368078\n",
       "news:3416291   296           3.760135       34.277027\n",
       "news:3416281   290           3.000000       60.313793\n",
       "news:3416289   267           3.239700       36.168539"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_usid</th>\n",
       "      <th>group_matches_in_window</th>\n",
       "      <th>matched_group_reps</th>\n",
       "      <th>reddit_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>source</th>\n",
       "      <th>reddit_permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>news:3416242</td>\n",
       "      <td>7</td>\n",
       "      <td>capitol anniversary,storm capitol,sich fünften...</td>\n",
       "      <td>Fifth anniversary of Jan. 6 brings fresh divis...</td>\n",
       "      <td>https://www.wral.com/news/ap/1ef8f-fifth-anniv...</td>\n",
       "      <td>new_politics</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1q5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>news:3416290</td>\n",
       "      <td>7</td>\n",
       "      <td>plädiert gericht,gericht schuldig,maduro plädi...</td>\n",
       "      <td>President Nicolas Maduro pleads not guilty to ...</td>\n",
       "      <td>https://www.reuters.com/world/americas/venezue...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/1q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10835</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>7</td>\n",
       "      <td>activists around,tote protesten,protesten iran...</td>\n",
       "      <td>Ban private jets, say scientists blocking airp...</td>\n",
       "      <td>https://prod.euronews.com/green/2023/02/14/act...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/112iw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10563</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>7</td>\n",
       "      <td>activists around,tote protesten,protesten iran...</td>\n",
       "      <td>Jewish activists form protective barrier aroun...</td>\n",
       "      <td>http://www.independent.co.uk/news/world/americ...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/6ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11002</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>7</td>\n",
       "      <td>activists around,tote protesten,protesten iran...</td>\n",
       "      <td>Protesters in cities around the world joined t...</td>\n",
       "      <td>http://thehill.com/blogs/blog-briefing-room/39...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/8v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>news:3415933</td>\n",
       "      <td>7</td>\n",
       "      <td>somalia military,schabab kämpfer,military kill...</td>\n",
       "      <td>Undeclared War: Obama's Robot Army Kills Dozen...</td>\n",
       "      <td>http://www.presstv.ir/detail/187978.html</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/ij2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>news:3415915</td>\n",
       "      <td>7</td>\n",
       "      <td>neuen protesten,protesten iran,dead new ones,m...</td>\n",
       "      <td>International media on the suspension of Nepsz...</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/56l27...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/56l27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10812</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>6</td>\n",
       "      <td>activists around,tote protesten,protesten iran...</td>\n",
       "      <td>Brexit protest around Buckingham Palace.</td>\n",
       "      <td>https://i.redd.it/pwlt45na7qwy.jpg</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/6af3h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15248</th>\n",
       "      <td>news:3416269</td>\n",
       "      <td>6</td>\n",
       "      <td>transferred to court,yorker gericht,new yorker...</td>\n",
       "      <td>Luigi Mangione in New York Court today!</td>\n",
       "      <td>https://i.redd.it/5h3s797j1n4g1.jpeg</td>\n",
       "      <td>search_en</td>\n",
       "      <td>https://www.reddit.com/r/pics/comments/1pbl2ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15250</th>\n",
       "      <td>news:3416269</td>\n",
       "      <td>6</td>\n",
       "      <td>transferred to court,yorker gericht,new yorker...</td>\n",
       "      <td>Luigi Mangione in New York Court today</td>\n",
       "      <td>https://i.redd.it/qfifn448616g1.jpeg</td>\n",
       "      <td>search_en</td>\n",
       "      <td>https://www.reddit.com/r/JoeRogan/comments/1ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>news:3415933</td>\n",
       "      <td>6</td>\n",
       "      <td>somalia military,schabab kämpfer,military kill...</td>\n",
       "      <td>U.S. Strikes Kill 150 Shabab Fighters in Somal...</td>\n",
       "      <td>http://nyti.ms/21WBuPg</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/news/comments/49e8fh/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>news:3416318</td>\n",
       "      <td>6</td>\n",
       "      <td>drohnenangriff russische,toter drohnenangriff,...</td>\n",
       "      <td>Secret Russian Counter-Drone EW System Recover...</td>\n",
       "      <td>https://www.kyivpost.com/post/37479</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/1e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15752</th>\n",
       "      <td>news:3416318</td>\n",
       "      <td>6</td>\n",
       "      <td>drohnenangriff russische,toter drohnenangriff,...</td>\n",
       "      <td>Major Russian Oil Refinery in Volgograd Region...</td>\n",
       "      <td>https://www.kyivpost.com/post/27558</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/1a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11182</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>6</td>\n",
       "      <td>activists around,tote protesten,protesten iran...</td>\n",
       "      <td>Crowds Gather Around the Country to Protest So...</td>\n",
       "      <td>https://nymag.com/intelligencer/2020/04/crowds...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/news/comments/g21qbq/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12354</th>\n",
       "      <td>news:3416290</td>\n",
       "      <td>6</td>\n",
       "      <td>plädiert gericht,gericht schuldig,maduro plädi...</td>\n",
       "      <td>'I Consider Myself a Prisoner of War,' Says Ma...</td>\n",
       "      <td>https://www.commondreams.org/news/nicolas-maduro</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1q4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_usid  group_matches_in_window  \\\n",
       "10101  news:3416242                        7   \n",
       "12340  news:3416290                        7   \n",
       "10835  news:3416296                        7   \n",
       "10563  news:3416296                        7   \n",
       "11002  news:3416296                        7   \n",
       "1401   news:3415933                        7   \n",
       "4291   news:3415915                        7   \n",
       "10812  news:3416296                        6   \n",
       "15248  news:3416269                        6   \n",
       "15250  news:3416269                        6   \n",
       "1453   news:3415933                        6   \n",
       "16186  news:3416318                        6   \n",
       "15752  news:3416318                        6   \n",
       "11182  news:3416296                        6   \n",
       "12354  news:3416290                        6   \n",
       "\n",
       "                                      matched_group_reps  \\\n",
       "10101  capitol anniversary,storm capitol,sich fünften...   \n",
       "12340  plädiert gericht,gericht schuldig,maduro plädi...   \n",
       "10835  activists around,tote protesten,protesten iran...   \n",
       "10563  activists around,tote protesten,protesten iran...   \n",
       "11002  activists around,tote protesten,protesten iran...   \n",
       "1401   somalia military,schabab kämpfer,military kill...   \n",
       "4291   neuen protesten,protesten iran,dead new ones,m...   \n",
       "10812  activists around,tote protesten,protesten iran...   \n",
       "15248  transferred to court,yorker gericht,new yorker...   \n",
       "15250  transferred to court,yorker gericht,new yorker...   \n",
       "1453   somalia military,schabab kämpfer,military kill...   \n",
       "16186  drohnenangriff russische,toter drohnenangriff,...   \n",
       "15752  drohnenangriff russische,toter drohnenangriff,...   \n",
       "11182  activists around,tote protesten,protesten iran...   \n",
       "12354  plädiert gericht,gericht schuldig,maduro plädi...   \n",
       "\n",
       "                                            reddit_title  \\\n",
       "10101  Fifth anniversary of Jan. 6 brings fresh divis...   \n",
       "12340  President Nicolas Maduro pleads not guilty to ...   \n",
       "10835  Ban private jets, say scientists blocking airp...   \n",
       "10563  Jewish activists form protective barrier aroun...   \n",
       "11002  Protesters in cities around the world joined t...   \n",
       "1401   Undeclared War: Obama's Robot Army Kills Dozen...   \n",
       "4291   International media on the suspension of Nepsz...   \n",
       "10812           Brexit protest around Buckingham Palace.   \n",
       "15248            Luigi Mangione in New York Court today!   \n",
       "15250             Luigi Mangione in New York Court today   \n",
       "1453   U.S. Strikes Kill 150 Shabab Fighters in Somal...   \n",
       "16186  Secret Russian Counter-Drone EW System Recover...   \n",
       "15752  Major Russian Oil Refinery in Volgograd Region...   \n",
       "11182  Crowds Gather Around the Country to Protest So...   \n",
       "12354  'I Consider Myself a Prisoner of War,' Says Ma...   \n",
       "\n",
       "                                                post_url        source  \\\n",
       "10101  https://www.wral.com/news/ap/1ef8f-fifth-anniv...  new_politics   \n",
       "12340  https://www.reuters.com/world/americas/venezue...     search_de   \n",
       "10835  https://prod.euronews.com/green/2023/02/14/act...     search_de   \n",
       "10563  http://www.independent.co.uk/news/world/americ...     search_de   \n",
       "11002  http://thehill.com/blogs/blog-briefing-room/39...     search_de   \n",
       "1401            http://www.presstv.ir/detail/187978.html     search_de   \n",
       "4291   https://www.reddit.com/r/europe/comments/56l27...     search_de   \n",
       "10812                 https://i.redd.it/pwlt45na7qwy.jpg     search_de   \n",
       "15248               https://i.redd.it/5h3s797j1n4g1.jpeg     search_en   \n",
       "15250               https://i.redd.it/qfifn448616g1.jpeg     search_en   \n",
       "1453                              http://nyti.ms/21WBuPg     search_de   \n",
       "16186                https://www.kyivpost.com/post/37479     search_de   \n",
       "15752                https://www.kyivpost.com/post/27558     search_de   \n",
       "11182  https://nymag.com/intelligencer/2020/04/crowds...     search_de   \n",
       "12354   https://www.commondreams.org/news/nicolas-maduro     search_de   \n",
       "\n",
       "                                        reddit_permalink  \n",
       "10101  https://www.reddit.com/r/politics/comments/1q5...  \n",
       "12340  https://www.reddit.com/r/worldnews/comments/1q...  \n",
       "10835  https://www.reddit.com/r/europe/comments/112iw...  \n",
       "10563  https://www.reddit.com/r/politics/comments/6ey...  \n",
       "11002  https://www.reddit.com/r/worldnews/comments/8v...  \n",
       "1401   https://www.reddit.com/r/politics/comments/ij2...  \n",
       "4291   https://www.reddit.com/r/europe/comments/56l27...  \n",
       "10812  https://www.reddit.com/r/europe/comments/6af3h...  \n",
       "15248  https://www.reddit.com/r/pics/comments/1pbl2ah...  \n",
       "15250  https://www.reddit.com/r/JoeRogan/comments/1ph...  \n",
       "1453   https://www.reddit.com/r/news/comments/49e8fh/...  \n",
       "16186  https://www.reddit.com/r/worldnews/comments/1e...  \n",
       "15752  https://www.reddit.com/r/worldnews/comments/1a...  \n",
       "11182  https://www.reddit.com/r/news/comments/g21qbq/...  \n",
       "12354  https://www.reddit.com/r/politics/comments/1q4...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_usid</th>\n",
       "      <th>group_matches_in_window</th>\n",
       "      <th>matched_group_reps</th>\n",
       "      <th>reddit_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>source</th>\n",
       "      <th>reddit_permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>news:3416269</td>\n",
       "      <td>3</td>\n",
       "      <td>transferred to court,yorker gericht,gericht</td>\n",
       "      <td>This Is the Nastiest Opinion by a Supreme Cour...</td>\n",
       "      <td>https://slate.com/news-and-politics/2026/01/su...</td>\n",
       "      <td>new_politics</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1q4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8885</th>\n",
       "      <td>news:3416301</td>\n",
       "      <td>3</td>\n",
       "      <td>new elections in venezuela,trump for now,venez...</td>\n",
       "      <td>Was Someone Insider Trading Right Before Trump...</td>\n",
       "      <td>https://newrepublic.com/post/204885/insider-tr...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1q3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>news:3416242</td>\n",
       "      <td>3</td>\n",
       "      <td>capitol anniversary,storm capitol,capitol</td>\n",
       "      <td>Purported neo-Nazis rally at South Dakota Stat...</td>\n",
       "      <td>https://www.thedakotascout.com/p/purported-neo...</td>\n",
       "      <td>search_en</td>\n",
       "      <td>https://www.reddit.com/r/news/comments/1dbisfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18569</th>\n",
       "      <td>news:3416305</td>\n",
       "      <td>3</td>\n",
       "      <td>grönland kämpfen,usa greenland,greenland</td>\n",
       "      <td>Retired US general says US ‘needs Europe’ to ‘...</td>\n",
       "      <td>https://tvpworld.com/90899221/ben-hodges-europ...</td>\n",
       "      <td>new_europe</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/1q5cq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11118</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>3</td>\n",
       "      <td>activists around,around dead,around</td>\n",
       "      <td>Soaring ocean temperatures have already cut th...</td>\n",
       "      <td>https://www.independent.co.uk/environment/fish...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>news:3416242</td>\n",
       "      <td>3</td>\n",
       "      <td>sich fünften,fünften mal,fünften</td>\n",
       "      <td>[Wien] Parken Möglichkeiten für Touristen für ...</td>\n",
       "      <td>https://www.reddit.com/r/Austria/comments/p3c4...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/Austria/comments/p3c4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>news:3415934</td>\n",
       "      <td>3</td>\n",
       "      <td>internationalen flugverkehr,stoppt internation...</td>\n",
       "      <td>Hungarian Parliament votes in favor of Hungary...</td>\n",
       "      <td>https://telex.hu/english/2025/05/20/hungarian-...</td>\n",
       "      <td>search_en</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/1k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>3</td>\n",
       "      <td>activists around,around dead,around</td>\n",
       "      <td>White House is expected to release a version o...</td>\n",
       "      <td>http://news.yahoo.com/on-the-torture-report--a...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/2b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>news:3416307</td>\n",
       "      <td>3</td>\n",
       "      <td>paris sicherheitsgarantien,beraten paris,paris</td>\n",
       "      <td>US officially rejoins the Paris climate accord</td>\n",
       "      <td>https://www.cnn.com/2021/02/19/politics/us-rej...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/lng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13367</th>\n",
       "      <td>news:3416290</td>\n",
       "      <td>3</td>\n",
       "      <td>plädiert gericht,gericht schuldig,gericht</td>\n",
       "      <td>Macrons to offer 'scientific evidence' to US c...</td>\n",
       "      <td>https://www.bbc.com/news/articles/ckg3llj5nxdo</td>\n",
       "      <td>search_en</td>\n",
       "      <td>https://www.reddit.com/r/news/comments/1njzxwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>news:3416307</td>\n",
       "      <td>3</td>\n",
       "      <td>paris sicherheitsgarantien,beraten paris,paris</td>\n",
       "      <td>US wasn't invited to summit of military repres...</td>\n",
       "      <td>https://newsukraine.rbc.ua/news/us-wasn-t-invi...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/1j8lw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18100</th>\n",
       "      <td>news:3416305</td>\n",
       "      <td>3</td>\n",
       "      <td>usa greenland,niemand usa,usa</td>\n",
       "      <td>Boris Pistorius just announced in Washington t...</td>\n",
       "      <td>https://v.redd.it/19zzqr2r7gzc1</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/1co50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>news:3416302</td>\n",
       "      <td>3</td>\n",
       "      <td>because of greenland,usa because of,niemand usa</td>\n",
       "      <td>EU nations may close their borders to US trave...</td>\n",
       "      <td>https://www.france24.com/en/20200623-european-...</td>\n",
       "      <td>search_en</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16226</th>\n",
       "      <td>news:3416318</td>\n",
       "      <td>5</td>\n",
       "      <td>drohnenangriff russische,russische region,regi...</td>\n",
       "      <td>Russia already has nuclear weapons in the Balt...</td>\n",
       "      <td>https://www.reuters.com/world/europe/russia-al...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/worldnews/comments/u3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>news:3416296</td>\n",
       "      <td>3</td>\n",
       "      <td>activists around,around dead,around</td>\n",
       "      <td>In rare televised address, Macron says Europe ...</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2018-1...</td>\n",
       "      <td>search_de</td>\n",
       "      <td>https://www.reddit.com/r/europe/comments/9ov87...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_usid  group_matches_in_window  \\\n",
       "15285  news:3416269                        3   \n",
       "8885   news:3416301                        3   \n",
       "9970   news:3416242                        3   \n",
       "18569  news:3416305                        3   \n",
       "11118  news:3416296                        3   \n",
       "9542   news:3416242                        3   \n",
       "970    news:3415934                        3   \n",
       "11124  news:3416296                        3   \n",
       "7558   news:3416307                        3   \n",
       "13367  news:3416290                        3   \n",
       "7298   news:3416307                        3   \n",
       "18100  news:3416305                        3   \n",
       "8771   news:3416302                        3   \n",
       "16226  news:3416318                        5   \n",
       "10902  news:3416296                        3   \n",
       "\n",
       "                                      matched_group_reps  \\\n",
       "15285        transferred to court,yorker gericht,gericht   \n",
       "8885   new elections in venezuela,trump for now,venez...   \n",
       "9970           capitol anniversary,storm capitol,capitol   \n",
       "18569           grönland kämpfen,usa greenland,greenland   \n",
       "11118                activists around,around dead,around   \n",
       "9542                    sich fünften,fünften mal,fünften   \n",
       "970    internationalen flugverkehr,stoppt internation...   \n",
       "11124                activists around,around dead,around   \n",
       "7558      paris sicherheitsgarantien,beraten paris,paris   \n",
       "13367          plädiert gericht,gericht schuldig,gericht   \n",
       "7298      paris sicherheitsgarantien,beraten paris,paris   \n",
       "18100                      usa greenland,niemand usa,usa   \n",
       "8771     because of greenland,usa because of,niemand usa   \n",
       "16226  drohnenangriff russische,russische region,regi...   \n",
       "10902                activists around,around dead,around   \n",
       "\n",
       "                                            reddit_title  \\\n",
       "15285  This Is the Nastiest Opinion by a Supreme Cour...   \n",
       "8885   Was Someone Insider Trading Right Before Trump...   \n",
       "9970   Purported neo-Nazis rally at South Dakota Stat...   \n",
       "18569  Retired US general says US ‘needs Europe’ to ‘...   \n",
       "11118  Soaring ocean temperatures have already cut th...   \n",
       "9542   [Wien] Parken Möglichkeiten für Touristen für ...   \n",
       "970    Hungarian Parliament votes in favor of Hungary...   \n",
       "11124  White House is expected to release a version o...   \n",
       "7558      US officially rejoins the Paris climate accord   \n",
       "13367  Macrons to offer 'scientific evidence' to US c...   \n",
       "7298   US wasn't invited to summit of military repres...   \n",
       "18100  Boris Pistorius just announced in Washington t...   \n",
       "8771   EU nations may close their borders to US trave...   \n",
       "16226  Russia already has nuclear weapons in the Balt...   \n",
       "10902  In rare televised address, Macron says Europe ...   \n",
       "\n",
       "                                                post_url        source  \\\n",
       "15285  https://slate.com/news-and-politics/2026/01/su...  new_politics   \n",
       "8885   https://newrepublic.com/post/204885/insider-tr...     search_de   \n",
       "9970   https://www.thedakotascout.com/p/purported-neo...     search_en   \n",
       "18569  https://tvpworld.com/90899221/ben-hodges-europ...    new_europe   \n",
       "11118  https://www.independent.co.uk/environment/fish...     search_de   \n",
       "9542   https://www.reddit.com/r/Austria/comments/p3c4...     search_de   \n",
       "970    https://telex.hu/english/2025/05/20/hungarian-...     search_en   \n",
       "11124  http://news.yahoo.com/on-the-torture-report--a...     search_de   \n",
       "7558   https://www.cnn.com/2021/02/19/politics/us-rej...     search_de   \n",
       "13367     https://www.bbc.com/news/articles/ckg3llj5nxdo     search_en   \n",
       "7298   https://newsukraine.rbc.ua/news/us-wasn-t-invi...     search_de   \n",
       "18100                    https://v.redd.it/19zzqr2r7gzc1     search_de   \n",
       "8771   https://www.france24.com/en/20200623-european-...     search_en   \n",
       "16226  https://www.reuters.com/world/europe/russia-al...     search_de   \n",
       "10902  https://www.bloomberg.com/news/articles/2018-1...     search_de   \n",
       "\n",
       "                                        reddit_permalink  \n",
       "15285  https://www.reddit.com/r/politics/comments/1q4...  \n",
       "8885   https://www.reddit.com/r/politics/comments/1q3...  \n",
       "9970   https://www.reddit.com/r/news/comments/1dbisfi...  \n",
       "18569  https://www.reddit.com/r/europe/comments/1q5cq...  \n",
       "11118  https://www.reddit.com/r/worldnews/comments/aw...  \n",
       "9542   https://www.reddit.com/r/Austria/comments/p3c4...  \n",
       "970    https://www.reddit.com/r/worldnews/comments/1k...  \n",
       "11124  https://www.reddit.com/r/worldnews/comments/2b...  \n",
       "7558   https://www.reddit.com/r/politics/comments/lng...  \n",
       "13367  https://www.reddit.com/r/news/comments/1njzxwa...  \n",
       "7298   https://www.reddit.com/r/europe/comments/1j8lw...  \n",
       "18100  https://www.reddit.com/r/europe/comments/1co50...  \n",
       "8771   https://www.reddit.com/r/worldnews/comments/he...  \n",
       "16226  https://www.reddit.com/r/worldnews/comments/u3...  \n",
       "10902  https://www.reddit.com/r/europe/comments/9ov87...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# TEST / AUDIT SCRIPT\n",
    "# =========================\n",
    "import pandas as pd\n",
    "\n",
    "OUT_CSV = \"reddit_posts_minimal.csv\"\n",
    "\n",
    "df_out = pd.read_csv(OUT_CSV, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Rows:\", len(df_out))\n",
    "print(\"Unique articles:\", df_out[\"article_usid\"].nunique())\n",
    "print(\"Unique reddit posts:\", df_out[\"reddit_id\"].nunique())\n",
    "print(\"\\nTop sources:\")\n",
    "print(df_out[\"source\"].value_counts().head(10))\n",
    "\n",
    "# --- per-article summary ---\n",
    "per_article = (\n",
    "    df_out.groupby(\"article_usid\")\n",
    "    .agg(\n",
    "        kept=(\"reddit_id\", \"count\"),\n",
    "        avg_group_matches=(\"group_matches_in_window\", \"mean\"),\n",
    "        avg_word_count=(\"checked_word_count\", \"mean\"),\n",
    "    )\n",
    "    .sort_values(\"kept\", ascending=False)\n",
    ")\n",
    "\n",
    "display(per_article.head(20))\n",
    "\n",
    "# --- quick noise inspection: top matches & random sample ---\n",
    "best = df_out.sort_values(\n",
    "    [\"group_matches_in_window\", \"checked_word_count\"],\n",
    "    ascending=[False, True]\n",
    ").head(15)\n",
    "\n",
    "rand = df_out.sample(min(15, len(df_out)), random_state=42)\n",
    "\n",
    "display(best[[\n",
    "    \"article_usid\", \"group_matches_in_window\", \"matched_group_reps\",\n",
    "    \"reddit_title\", \"post_url\", \"source\", \"reddit_permalink\"\n",
    "]])\n",
    "\n",
    "display(rand[[\n",
    "    \"article_usid\", \"group_matches_in_window\", \"matched_group_reps\",\n",
    "    \"reddit_title\", \"post_url\", \"source\", \"reddit_permalink\"\n",
    "]])\n",
    "\n",
    "# --- optional: look at one specific article id quickly ---\n",
    "# example:\n",
    "# aid = \"news:3415936\"\n",
    "# display(df_out[df_out[\"article_usid\"] == aid].head(50))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
